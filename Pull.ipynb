{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What this notebook is for:\n",
    "This notebook looks at understanding ChatGPT's ability to select the needed function to be called, from a user's prompt\n",
    "\n",
    "*BIG IDEA*: The main idea may be illustrated using examples -\n",
    "\n",
    "When the following prompt is inputted: Give me the 10 most qualified react developers in Lagos, I expect that a function related to talent search on the Loubby platform, particularly the getTalents function is called, and the necessary parameters are given.\n",
    "\n",
    "This notebook exists to highlight the process behind obtaining this desired result, and understanding ChatGPT's ability to generate the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import datetime\n",
    "import key\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "import openai\n",
    "import json\n",
    "\n",
    "from langchain.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "chat = ChatOpenAI(temperature=0.7, model='gpt-4-1106-preview', api_key=key.OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_embedding function that converts string to vectors \n",
    "def generate_embedding(text: str) -> list[float]:\n",
    "    query_vector = embeddings.embed_query(text)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating connection to the loubbydb using the connection string\n",
    "client = pymongo.MongoClient(key.Loubby_string)\n",
    "client.admin.command('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the loubby database and collection \n",
    "db = client.loubbyDb\n",
    "action_collection = db.actionSpaceText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG doesn't work except when the conventional text dump is done, by manually adding text. However, what is currently on ground is the actionSpace as a \n",
    "\n",
    "collection with documents (just like a table). So, 2 branches of the experiment will occur.\n",
    "\n",
    "Continue with the current schema, and manually perform RAG.\n",
    "Turn the actionSpace information to a list of strings containing all pieces of information that we currently have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Continuing with current schema and manually performing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"text_response\": \"I have executed the 'getTalents' function to search for 10 data scientists in Lagos.\",\n",
      "  \"function_name\": \"getTalents\",\n",
      "  \"parameters\": {\n",
      "    \"jobType\": {\"fullTime\": true, \"partTime\": false, \"contract\": false, \"internship\": false, \"remote\": false},\n",
      "    \"professionalLevel\": {\"entryLevel\": false, \"juniorLevel\": true, \"middleLevel\": true, \"seniorLevel\": true, \"directorLevel\": false, \"VPabove\": false},\n",
      "    \"country\": \"Nigeria\",\n",
      "    \"experienceYears\": \"Not specified\",\n",
      "    \"degrees\": \"Not specified\",\n",
      "    \"skills\": [\"Data Science\"],\n",
      "    \"role\": \"Data Scientist\",\n",
      "    \"state\": \"Lagos (LOS)\"\n",
      "  },\n",
      "  \"front_end_url\": \"https://app.loubby.ai/dashboard/talents\",\n",
      "  \"back_end_url\": \"https://api.loubby.ai/api/v1/user/info\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "explanation = \"\"\"\n",
    "\n",
    "{'task': 'Talent search', 'function_name': 'getTalents', 'frontend_url': '/dashboard/talents', 'backend_url': '/user/info', 'parameters/args': \n",
    "'jobType, professionalLevel, country,  experienceYears, degrees, skill, role, state ', 'Parameter Description': \"['jobType' -> Takes a JSON object with the \n",
    "following keys (fullTime, partTime, contract, internship, remote) and boolean values (example {'fullTime': True, 'partTime': True, 'contract': False, 'internship': \n",
    "False, 'remote': False});\\n\\n'professionalLevel' -> Takes a JSON object with the following keys (entryLevel, juniorLevel, middleLevel, seniorLevel, directorLevel,\n",
    " VPabove) and boolean values (example {'entryLevel': True, 'juniorLevel': True, 'middleLevel': False, 'seniorLevel': False, 'directorLevel': False, \n",
    " 'VPabove': True});\\n\\n'country' -> Takes a string corresponding country names example 'Nigeria', 'United States', 'China';\\n\\n'experienceYears' -> Takes a string \n",
    " from one of '0-2 experience years', '2-5 experience years', '5-10 experience years';\\n\\n'degrees' -> Takes a string from one of 'Bachelor's Degree', 'Master's \n",
    " Degree', 'PhD';\\n\\n'skills' -> Takes a list of strings highlighting the candidate(s)'s skills example ['Python', 'Java', 'React', 'Node', 'JavaScript', 'SQL', \n",
    " 'Tableau', 'Laveral', 'Flutter'];\\n\\n'role' -> A string highlighting the job headline, example 'Data Analyst', 'Software Engineer', 'Chef';\\n\\n'state' -> A \n",
    " string highlighting the state in the country where the candidate(s) reside(s) and the state code in parentheses example ['Abuja (ABJ)', 'Texas (TX)', 'London \n",
    " (LDN)']\", 'descriptions': 'returns information about candidates / job seekers / talents based on the arguments passed', 'rest_api': 'GET', 'front_endpoints': '\n",
    " https://https://app.loubby.ai/dashboard/talents', 'back_endpoints': 'https://api.loubby.ai/api/v1/user/info'}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "template = 'Explanation: {explanation} \\n\\nquery: {query}'\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['query'],\n",
    "    template=template,\n",
    "    partial_variables={'explanation': explanation}\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7, model='gpt-4-1106-preview')\n",
    "\n",
    "ourConvo = chat([\n",
    "    SystemMessage(content=\"You are a bot for the Loubby AI product, and you are called Jabbari. For the query, you are to output a JSON containing: 1) a text response from you which could either be a follow up question (if the user's query is VAGUE or NOT CLOSE TO SPECIFIC) or just a response to tell the user that you've done what they've asked; 2) The function name; 3) The approproate values of each parameter, also given in JSON format; 4) front end URL 5) back end URL\"),\n",
    "    HumanMessage(content = prompt.format(query = 'Find me 10 data scientists in Lagos'))\n",
    "])\n",
    "\n",
    "print(ourConvo.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Try implementing RAG straight away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStore = MongoDBAtlasVectorSearch(collection=action_collection, embedding=embeddings, index_name='action-description-index', text_key='func_doc', embedding_key='embedded_description')\n",
    "retriever = vectorStore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI must have scrapped the normal completions endpoint, because the models that support it have been deprecated. Let's try the chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{question}\n",
    "\n",
    "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, response \n",
    "with \"I don't know\"\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nCONTEXT:\\n{context}\\n\\nQUERY:\\n{question}\\n\\nUse the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, response with \"I don\\'t know\"\\n'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Experiment 2: Turn the actionSpace to a list of strings and perform RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStore = MongoDBAtlasVectorSearch(collection=action_collection, embedding=embeddings, index_name='action-description-index', text_key='func_doc', embedding_key='embedded_description')\n",
    "retriever = vectorStore.as_retriever(search_type = 'mmr', search_kwargs ={'fetch_k': 4, 'k': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refer to Paul's notebook for the data preprocessing and collection creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To get information on candidates, you can call the `getTalents` function. This function retrieves talent/candidates information from the Loubby AI database based on specified parameters such as job type, professional level, country, experience years, degrees, skills, role, and state.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(chat, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "rag_chain.run('What function can I call to get information on candidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It works. So, let's add a conversation functionality to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, memory_key='chat_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a bot for the Loubby AI product, and your name is Jabbari. Given context and a query, you are to output a JSON containing: 1) a text response from you [Key name: text_response], (as if in conversation with the user) which may be a follow up question (if you need more clarity) or any other appropriate response; 2) The function name [Key name: function_name]; 3) The appropriate values of each parameter [Key name: params], also given in JSON format, if a parameter is not implied by the user, then do not include it; 4) front end endpoint [Key name: front_endpoint]; 5) back end point [Key name: back_endpoint]. If the query does not correlate to the context, then, output ONLY the response in item 1)\n",
      "Human: context:\n",
      "{'task': 'Create Job', 'function_name': 'createJob', 'frontend_url': '/dashboard/jobs/joblisting', 'backend_url': '/employer/listing/create', 'parameters/args': 'jobTitle, jobDescription, jobType,  jobLocation, jobSalary, rateCurrency, jobSalaryMin, jobSalaryMax, salaryCurrency, jobRate, applicationDeadline, numberOfPositions, openToRemote, perks, jobSkills', 'Parameter Description': '', 'descriptions': 'Give me 5 data scientist in Nigeria, Find 14 senior MERN developers, Show me 3 chefs that have good communication skills.', 'rest_api': 'POST', 'front_endpoints': 'https://app.loubby.ai/dashboard/jobs/joblisting', 'back_endpoints': 'https://api.loubby.ai/api/v1/employer/listing/create'}\n",
      "\n",
      "{'task': 'Talent search', 'function_name': 'getTalents', 'frontend_url': '/dashboard/talents', 'backend_url': '/user/info', 'parameters/args': 'jobType, professionalLevel, country,  experienceYears, degrees, skill, role, state ', 'Parameter Description': \"['jobType' -> Takes a JSON object with the following keys (fullTime, partTime, contract, internship, remote) and boolean values (example {'fullTime': True, 'partTime': True, 'contract': False, 'internship': False, 'remote': False});\\n\\n'professionalLevel' -> Takes a JSON object with the following keys (entryLevel, juniorLevel, middleLevel, seniorLevel, directorLevel, VPabove) and boolean values (example {'entryLevel': True, 'juniorLevel': True, 'middleLevel': False, 'seniorLevel': False, 'directorLevel': False, 'VPabove': True});\\n\\n'country' -> Takes a string corresponding country names example 'Nigeria', 'United States', 'China';\\n\\n'experienceYears' -> Takes a string from one of '0-2 experience years', '2-5 experience years', '5-10 experience years';\\n\\n'degrees' -> Takes a string from one of 'Bachelor's Degree', 'Master's Degree', 'PhD';\\n\\n'skills' -> Takes a list of strings highlighting the candidate(s)'s skills example ['Python', 'Java', 'React', 'Node', 'JavaScript', 'SQL', 'Tableau', 'Laveral', 'Flutter'];\\n\\n'role' -> A string highlighting the job headline, example 'Data Analyst', 'Software Engineer', 'Chef';\\n\\n'state' -> A string highlighting the state in the country where the candidate(s) reside(s) and the state code in parentheses example ['Abuja (ABJ)', 'Texas (TX)', 'London (LDN)']\", 'descriptions': \"The 'getTalents' function retrieves talent / candidates information from the Loubby AI database based on specified parameters. This function is designed to facilitate searching and filtering of talents to meet specific criteria. The talent database contains comprehensive information about individuals with various skills, expertise, and qualifications.\", 'rest_api': 'GET', 'front_endpoints': 'https://https://app.loubby.ai/dashboard/talents', 'back_endpoints': 'https://api.loubby.ai/api/v1/user/info'} \n",
      "\n",
      "query:\n",
      "Siri, give me 5 data scientists\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Siri, give me 5 data scientists',\n",
       " 'chat_history': [HumanMessage(content='Siri, give me 5 data scientists'),\n",
       "  AIMessage(content='```json\\n{\\n  \"text_response\": \"Just to clarify, are you looking for 5 data scientists available for job opportunities, or do you want to create a job listing for a data scientist position?\",\\n  \"function_name\": \"\",\\n  \"params\": {},\\n  \"front_endpoint\": \"\",\\n  \"back_endpoint\": \"\"\\n}\\n```')],\n",
       " 'answer': '```json\\n{\\n  \"text_response\": \"Just to clarify, are you looking for 5 data scientists available for job opportunities, or do you want to create a job listing for a data scientist position?\",\\n  \"function_name\": \"\",\\n  \"params\": {},\\n  \"front_endpoint\": \"\",\\n  \"back_endpoint\": \"\"\\n}\\n```'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "memory.clear()\n",
    "\n",
    "qa_system_template = \"\"\"You are a bot for the Loubby AI product, and your name is Jabbari. Given context and a query, you are to output a JSON containing: \n",
    "1) a text response from you [Key name: text_response], (as if in conversation with the user) which may be a follow up question (if you need more clarity) or \n",
    "any other appropriate response; 2) The function name [Key name: function_name]; 3) The appropriate values of each parameter [Key name: params], also given in \n",
    "JSON format, if a parameter is not implied by the user, then do not include it; 4) front end endpoint [Key name: front_endpoint]; 5) back end point [Key name: \n",
    "back_endpoint]. If the query does not correlate to the context, then, output ONLY the response in item 1)\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(qa_system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"context:\\n{context} \\n\\nquery:\\n{question}\"),\n",
    "]\n",
    "qa_system_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "qa = ConversationalRetrievalChain.from_llm(chat, vectorStore.as_retriever(search_kwargs={\n",
    "                                            \"k\": 2}), memory=memory,\n",
    "                                            verbose=True, combine_docs_chain_kwargs={\"prompt\": qa_system_prompt})\n",
    "                                            \n",
    "question = \"Siri, give me 5 data scientists\"\n",
    "\n",
    "qa({'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"text_response\": \"Just to clarify, are you looking for 5 data scientists available for job opportunities, or do you want to create a job listing for a data scientist position?\",\n",
      "  \"function_name\": \"\",\n",
      "  \"params\": {},\n",
      "  \"front_endpoint\": \"\",\n",
      "  \"back_endpoint\": \"\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(memory.chat_memory.messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Siri, give me 5 data scientists\n",
      "Assistant: ```json\n",
      "{\n",
      "  \"text_response\": \"Just to clarify, are you looking for 5 data scientists available for job opportunities, or do you want to create a job listing for a data scientist position?\",\n",
      "  \"function_name\": \"\",\n",
      "  \"params\": {},\n",
      "  \"front_endpoint\": \"\",\n",
      "  \"back_endpoint\": \"\"\n",
      "}\n",
      "```\n",
      "Human: Give me 14 front end developers in Nigeria\n",
      "Assistant: ```json\n",
      "{\n",
      "  \"text_response\": \"Sure, I can help you with that. Would you like to specify any particular skills, experience level, or professional level for these front-end developers?\",\n",
      "  \"function_name\": \"getTalents\",\n",
      "  \"params\": {\n",
      "    \"jobType\": {\"fullTime\": true, \"partTime\": true, \"contract\": true, \"internship\": false, \"remote\": true},\n",
      "    \"professionalLevel\": {\"entryLevel\": true, \"juniorLevel\": true, \"middleLevel\": true, \"seniorLevel\": true, \"directorLevel\": false, \"VPabove\": false},\n",
      "    \"country\": \"Nigeria\",\n",
      "    \"role\": \"Front-end Developer\"\n",
      "  },\n",
      "  \"front_endpoint\": \"https://https://app.loubby.ai/dashboard/talents\",\n",
      "  \"back_endpoint\": \"https://api.loubby.ai/api/v1/user/info\"\n",
      "}\n",
      "```\n",
      "Follow Up Input: Give me 14 front end developers in Nigeria\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a bot for the Loubby AI product, and your name is Jabbari. Given context and a query, you are to output a JSON containing: 1) a text response from you [Key name: text_response], (as if in conversation with the user) which may be a follow up question (if you need more clarity) or any other appropriate response; 2) The function name [Key name: function_name]; 3) The appropriate values of each parameter [Key name: params], also given in JSON format, if a parameter is not implied by the user, then do not include it; 4) front end endpoint [Key name: front_endpoint]; 5) back end point [Key name: back_endpoint]. If the query does not correlate to the context, then, output ONLY the response in item 1)\n",
      "Human: context:\n",
      "{'task': 'Create Job', 'function_name': 'createJob', 'frontend_url': '/dashboard/jobs/joblisting', 'backend_url': '/employer/listing/create', 'parameters/args': 'jobTitle, jobDescription, jobType,  jobLocation, jobSalary, rateCurrency, jobSalaryMin, jobSalaryMax, salaryCurrency, jobRate, applicationDeadline, numberOfPositions, openToRemote, perks, jobSkills', 'Parameter Description': '', 'descriptions': 'Give me 5 data scientist in Nigeria, Find 14 senior MERN developers, Show me 3 chefs that have good communication skills.', 'rest_api': 'POST', 'front_endpoints': 'https://app.loubby.ai/dashboard/jobs/joblisting', 'back_endpoints': 'https://api.loubby.ai/api/v1/employer/listing/create'}\n",
      "\n",
      "{'task': 'Talent search', 'function_name': 'getTalents', 'frontend_url': '/dashboard/talents', 'backend_url': '/user/info', 'parameters/args': 'jobType, professionalLevel, country,  experienceYears, degrees, skill, role, state ', 'Parameter Description': \"['jobType' -> Takes a JSON object with the following keys (fullTime, partTime, contract, internship, remote) and boolean values (example {'fullTime': True, 'partTime': True, 'contract': False, 'internship': False, 'remote': False});\\n\\n'professionalLevel' -> Takes a JSON object with the following keys (entryLevel, juniorLevel, middleLevel, seniorLevel, directorLevel, VPabove) and boolean values (example {'entryLevel': True, 'juniorLevel': True, 'middleLevel': False, 'seniorLevel': False, 'directorLevel': False, 'VPabove': True});\\n\\n'country' -> Takes a string corresponding country names example 'Nigeria', 'United States', 'China';\\n\\n'experienceYears' -> Takes a string from one of '0-2 experience years', '2-5 experience years', '5-10 experience years';\\n\\n'degrees' -> Takes a string from one of 'Bachelor's Degree', 'Master's Degree', 'PhD';\\n\\n'skills' -> Takes a list of strings highlighting the candidate(s)'s skills example ['Python', 'Java', 'React', 'Node', 'JavaScript', 'SQL', 'Tableau', 'Laveral', 'Flutter'];\\n\\n'role' -> A string highlighting the job headline, example 'Data Analyst', 'Software Engineer', 'Chef';\\n\\n'state' -> A string highlighting the state in the country where the candidate(s) reside(s) and the state code in parentheses example ['Abuja (ABJ)', 'Texas (TX)', 'London (LDN)']\", 'descriptions': \"The 'getTalents' function retrieves talent / candidates information from the Loubby AI database based on specified parameters. This function is designed to facilitate searching and filtering of talents to meet specific criteria. The talent database contains comprehensive information about individuals with various skills, expertise, and qualifications.\", 'rest_api': 'GET', 'front_endpoints': 'https://https://app.loubby.ai/dashboard/talents', 'back_endpoints': 'https://api.loubby.ai/api/v1/user/info'} \n",
      "\n",
      "query:\n",
      "Can you provide a list of 14 front-end developers located in Nigeria?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Give me 14 front end developers in Nigeria',\n",
       " 'chat_history': [HumanMessage(content='Siri, give me 5 data scientists'),\n",
       "  AIMessage(content='```json\\n{\\n  \"text_response\": \"Just to clarify, are you looking for 5 data scientists available for job opportunities, or do you want to create a job listing for a data scientist position?\",\\n  \"function_name\": \"\",\\n  \"params\": {},\\n  \"front_endpoint\": \"\",\\n  \"back_endpoint\": \"\"\\n}\\n```'),\n",
       "  HumanMessage(content='Give me 14 front end developers in Nigeria'),\n",
       "  AIMessage(content='```json\\n{\\n  \"text_response\": \"Sure, I can help you with that. Would you like to specify any particular skills, experience level, or professional level for these front-end developers?\",\\n  \"function_name\": \"getTalents\",\\n  \"params\": {\\n    \"jobType\": {\"fullTime\": true, \"partTime\": true, \"contract\": true, \"internship\": false, \"remote\": true},\\n    \"professionalLevel\": {\"entryLevel\": true, \"juniorLevel\": true, \"middleLevel\": true, \"seniorLevel\": true, \"directorLevel\": false, \"VPabove\": false},\\n    \"country\": \"Nigeria\",\\n    \"role\": \"Front-end Developer\"\\n  },\\n  \"front_endpoint\": \"https://https://app.loubby.ai/dashboard/talents\",\\n  \"back_endpoint\": \"https://api.loubby.ai/api/v1/user/info\"\\n}\\n```'),\n",
       "  HumanMessage(content='Give me 14 front end developers in Nigeria'),\n",
       "  AIMessage(content='```json\\n{\\n  \"text_response\": \"Sure, I can help you with that. Just to clarify, are you looking for any specific professional level or years of experience for these front-end developers?\",\\n  \"function_name\": \"getTalents\",\\n  \"params\": {\\n    \"jobType\": {\\n      \"fullTime\": true,\\n      \"partTime\": false,\\n      \"contract\": false,\\n      \"internship\": false,\\n      \"remote\": false\\n    },\\n    \"country\": \"Nigeria\",\\n    \"role\": \"Front-end Developer\"\\n  },\\n  \"front_endpoint\": \"https://app.loubby.ai/dashboard/talents\",\\n  \"back_endpoint\": \"https://api.loubby.ai/api/v1/user/info\"\\n}\\n```')],\n",
       " 'answer': '```json\\n{\\n  \"text_response\": \"Sure, I can help you with that. Just to clarify, are you looking for any specific professional level or years of experience for these front-end developers?\",\\n  \"function_name\": \"getTalents\",\\n  \"params\": {\\n    \"jobType\": {\\n      \"fullTime\": true,\\n      \"partTime\": false,\\n      \"contract\": false,\\n      \"internship\": false,\\n      \"remote\": false\\n    },\\n    \"country\": \"Nigeria\",\\n    \"role\": \"Front-end Developer\"\\n  },\\n  \"front_endpoint\": \"https://app.loubby.ai/dashboard/talents\",\\n  \"back_endpoint\": \"https://api.loubby.ai/api/v1/user/info\"\\n}\\n```'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Give me 14 front end developers in Nigeria\"\n",
    "\n",
    "qa({'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"text_response\": \"Sure, I can help you with that. Would you like to specify any particular skills, experience level, or professional level for these front-end developers?\",\n",
      "  \"function_name\": \"getTalents\",\n",
      "  \"params\": {\n",
      "    \"jobType\": {\"fullTime\": true, \"partTime\": true, \"contract\": true, \"internship\": false, \"remote\": true},\n",
      "    \"professionalLevel\": {\"entryLevel\": true, \"juniorLevel\": true, \"middleLevel\": true, \"seniorLevel\": true, \"directorLevel\": false, \"VPabove\": false},\n",
      "    \"country\": \"Nigeria\",\n",
      "    \"role\": \"Front-end Developer\"\n",
      "  },\n",
      "  \"front_endpoint\": \"https://https://app.loubby.ai/dashboard/talents\",\n",
      "  \"back_endpoint\": \"https://api.loubby.ai/api/v1/user/info\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(memory.chat_memory.messages[3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"keys\": [\n",
      "            \"name\",\n",
      "            \"age\"\n",
      "        ],\n",
      "        \"values\": [\n",
      "            \"Alice\",\n",
      "            30\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"keys\": [\n",
      "            \"name\",\n",
      "            \"age\"\n",
      "        ],\n",
      "        \"values\": [\n",
      "            \"Bob\",\n",
      "            25\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"keys\": [\n",
      "            \"name\",\n",
      "            \"age\"\n",
      "        ],\n",
      "        \"values\": [\n",
      "            \"Charlie\",\n",
      "            35\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_list = [\n",
    "    {'name': 'Alice', 'age': 30},\n",
    "    {'name': 'Bob', 'age': 25},\n",
    "    {'name': 'Charlie', 'age': 35}\n",
    "]\n",
    "\n",
    "output = []\n",
    "\n",
    "for item in data_list:\n",
    "    if isinstance(item, dict):\n",
    "        output.append({\n",
    "            'keys': list(item.keys()),\n",
    "            'values': list(item.values())\n",
    "        })\n",
    "\n",
    "# Print the output in JSON format\n",
    "print(json.dumps(output, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requirements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
